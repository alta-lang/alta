import uint32, Size from "types"
import Vector from "vector"
import String, CodePoint from "string"
import Path from "fs"
import Map from "map"
import Pair from "util"
import Queue from "queue"

export class Location {
	public var line: Size
	public var column: Size
	public var index: Size
	public var file: Path

	public constructor(line: Size = 0, column: Size = 0, index: Size = 0, file: Path = new Path) {
		this.line = line
		this.column = column
		this.index = index
		this.file = file
	}
}

export enum TokenType: Size {
	None, # should never be used
	AtSign,
	Identifier,
	OpeningParenthesis,
	ClosingParenthesis,
	OpeningBrace,
	ClosingBrace,
	Number,
	Equality,
	EqualSign,
	Dot,
	Colon,
	Comma,
	Ampersand,
	Asterisk,
	String,
	Last, # TODO: the next update to the language should support this as a property on enums (like e.g. `MyEnum.$first` and `MyEnum.$last`)
	      #       note that i used the special fetch notation there because we want to avoid reserving enumeration member names
}

# @brief tokens that don't need special logic; they just need to be found in their entirety
let staticTokens = new Map<String, TokenType>(items:
	new Pair<String, TokenType>("@", TokenType.AtSign),
	new Pair<String, TokenType>("==", TokenType.Equality),
	new Pair<String, TokenType>("=", TokenType.EqualSign),
	new Pair<String, TokenType>(".", TokenType.Dot),
	new Pair<String, TokenType>("{", TokenType.OpeningBrace),
	new Pair<String, TokenType>("}", TokenType.ClosingBrace),
	new Pair<String, TokenType>("(", TokenType.OpeningParenthesis),
	new Pair<String, TokenType>(")", TokenType.ClosingParenthesis),
	new Pair<String, TokenType>(":", TokenType.Colon),
	new Pair<String, TokenType>(",", TokenType.Comma),
	new Pair<String, TokenType>("&", TokenType.Ampersand),
	new Pair<String, TokenType>("*", TokenType.Asterisk),
)

export class Token {
	public var type: TokenType
	public var content: String
	public var location: Location = new Location

	public constructor(type: TokenType, content: String = "", location: Location = new Location) {
		this.type = type
		this.content = content
		this.location = location
	}

	public to String {
		return this.content
	}
}

function isIdentifierNonFirst(cp: uint32): bool {
	return (cp >= 'A' && cp <= 'Z') || (cp >= 'a' && cp <= 'z') || (cp >= '0' && cp <= '9') || cp == '_'
}

# this could probably be split up into different coroutines like the parser is going to be,
# but the lexer is small and simple enough that we can try to be as efficient as possible
# by processing everything in this one single generator
generator function process(file: Path)(uint32...): Token? {
	let token: Token? = null
	let cpQueue: Queue<uint32>
	let line: Size = 1
	let column: Size = 0
	while true {
		# this block here is frequently repeated throughout this generator
		# it's used to get a character; first by looking in the backlog/queue,
		# and then by asking for more characters
		# TODO: the next version of Alta (the one being implemented by this bootstrapped compiler)
		#       should have a macro system (but not that crappy copy-pasting kind like C/C++ has)
		let pendingCP: uint32? = null
		if cpQueue.length > 0
			pendingCP = cpQueue.pop()
		if !pendingCP {
			pendingCP = yield token
			token = null
		}

		# if we don't have a pending token, we're done
		if !pendingCP
			return token

		# we got a character, so increment our column counter
		++column
		let cp = *pendingCP

		if (cp >= 'A' && cp <= 'Z') || (cp >= 'a' && cp <= 'z') || cp == '_' {
			let tok = new Token(TokenType.Identifier, location: new Location(line: line, column: column, file: file))
			tok.content += cp

			let continueIt = false
			let breakOut = false
			while true {
				let maybeCP: uint32? = null
				if cpQueue.length > 0
					maybeCP = cpQueue.pop()
				if !maybeCP {
					maybeCP = yield token
					token = null
				}

				if !maybeCP {
					breakOut = true
					break
				}

				++column
				let cp2 = *maybeCP

				if !isIdentifierNonFirst(cp2) {
					--column
					cpQueue.push(cp2)
					continueIt = true
					break
				}

				tok.content += cp2
			}

			token = tok

			if breakOut
				break
			if continueIt
				continue
		} else if cp >= '0' && cp <= '9' {
			let tok = new Token(TokenType.Number, location: new Location(line: line, column: column, file: file))
			tok.content += cp

			let continueIt = false
			let breakOut = false
			while true {
				let maybeCP: uint32? = null
				if cpQueue.length > 0
					maybeCP = cpQueue.pop()
				if !maybeCP {
					maybeCP = yield token
					token = null
				}

				if !maybeCP {
					breakOut = true
					break
				}

				++column
				let cp2 = *maybeCP

				if !(cp2 >= '0' && cp2 <= '9') {
					--column
					cpQueue.push(cp2)
					continueIt = true
					break
				}

				tok.content += cp2
			}

			token = tok

			if breakOut
				break
			if continueIt
				continue
		} else if cp == '"' {
			let tok = new Token(TokenType.String, location: new Location(line: line, column: column, file: file))
			tok.content += cp

			let escapeIt = false
			let breakOut = false
			let continueIt = false
			let ok = true
			while true {
				let maybeCP: uint32? = null
				if cpQueue.length > 0
					maybeCP = cpQueue.pop()
				if !maybeCP {
					maybeCP = yield token
					token = null
				}

				if !maybeCP {
					breakOut = true
					break
				}

				let cp2 = *maybeCP

				if cp2 == '\r' || cp2 == '\n' {
					let cps = new Queue<uint32>
					for item: CodePoint in tok.content.items {
						cps.push(item)
					}
					cps.push(cp2)
					while cpQueue.length > 0
						cps.push(cpQueue.pop())
					cpQueue = cps
					continueIt = true
					ok = false
					break
				} else if escapeIt {
					escapeIt = false
					tok.content += cp2
				} else if cp2 == '\\' {
					escapeIt = true
					tok.content += '\\'
				} else if cp2 == '"' {
					tok.content += cp2
					break
				} else {
					tok.content += cp2
				}
			}

			if ok {
				token = tok
				column += tok.content.length - 1
			}

			if breakOut
				break
			if continueIt
				continue
		} else if cp == ' ' || cp == '\t' {
			# no-op
		} else if cp == '\r' {
			++line
			column = 0

			# the following code block provides support for Windows-style '\r\n' (CRLF) EOLs
			# without it, we would only support "Old Mac OS"-style '\r' (CR) and Unix-style '\n' (LF) EOLs
			# (i personally prefer LF everywhere, no matter what system i'm on, but i'd rather not enforce that on everyone else)
			let maybeCP: uint32? = null
			if cpQueue.length > 0
				maybeCP = cpQueue.pop()
			if !maybeCP {
				maybeCP = yield token
				token = null
			}
			if maybeCP && *maybeCP != '\n'
				cpQueue.push(*maybeCP)
		} else if cp == '\n' {
			++line
			column = 0
		} else {
			# determine how many static tokens are possible matches based on the first character
			let viable = new Vector<Pair<String, TokenType>>
			for candidate: Pair<String, TokenType> in staticTokens.items {
				if candidate.first[0] == cp {
					viable.push(candidate)
				}
			}

			let idx: Size = 1
			let continueIt = false
			let breakOut = false

			# @brief Queue of all the codepoints we've examined
			# @desc Why do we have this? So that we don't discard characters if we end up
			#       asking for more than we actually needed.
			#       "But we'll only ever ask for one more character than our longest candidate, right?"
			#       Right, but that candidate can get popped off before we process the final result,
			#       so we need to keep track of our characters separately
			let processedCPs = new Queue<uint32>

			while viable.length > 0 {
				# determine the current longest candidate
				let maxLength: Size = 0
				for i: Size in 0..viable.length {
					if viable[i].first.length > maxLength
						maxLength = viable[i].first.length
				}

				# if the current character index is greater than the length of the longest possible candidate,
				# we're done asking for characters; make do with what we have
				if idx > maxLength
					break

				let maybeCP: uint32? = null
				if cpQueue.length > 0
					maybeCP = cpQueue.pop()
				if !maybeCP {
					maybeCP = yield token
					token = null
				}

				if !maybeCP {
					breakOut = true
					# we reached the end of our character stream; we won't be getting any more characters,
					# so remove any candidates that still haven't been satisfied
					for i: Size in 0..viable.length {
						if viable[i].first.length > idx {
							viable.remove(i)
							--i
						}
					}
					break
				} else {
					processedCPs.push(*maybeCP)
					# look for and remove candidates that don't have the character we got as their next character
					for i: Size in 0..viable.length {
						if viable[i].first.length > idx {
							if viable[i].first[idx] != *maybeCP {
								viable.remove(i)
								--i
							}
						}
					}
					++idx
				}
			}
			if viable.length > 0 {
				# find the longest match and use that
				let maxLength: Size = 0
				for candidate: ref Pair<String, TokenType> in viable.items {
					if candidate.first.length > maxLength {
						maxLength = candidate.first.length
						token = new Token(candidate.second, content: candidate.first, location: new Location(line: line, column: column, file: file))
					}
				}
				# pop off the characters we consumed
				for i: Size in 1..(*token).content.length {
					processedCPs.pop()
				}
				# advance the column counter by the number of tokens we consumed minus 1
				# (because we already incremented for it earlier)
				column += (*token).content.length - 1
			} else {
				# TODO: somehow tell the user that we failed to lex something
			}

			# push back the characters we didn't use
			while cpQueue.length > 0
				processedCPs.push(cpQueue.pop())
			# and replace the queue
			cpQueue = processedCPs

			if breakOut
				break
			if continueIt
				continue
		}
	}
	return token
}

# @brief A fully streaming lexer for Alta
# @desc This lexer is generator-based, it will only process what you give it.
#       The current version is coded to push tokens onto a result vector, but the lexer is set up in a way
#       that the API can be quickly and easily changed to also pass you the tokens in a streaming manner.
export class Lexer {
	private var gen: (@returnTypeOf process)? = null

	public var tokens: Vector<Token>

	public constructor(file: Path) {
		this.gen = process(file)
		# needs to advance to the first `yield`
		;(*this.gen).next()
	}

	public function feed(input: CodePoint): void {
		if let maybeMaybeTok = (*this.gen).next(input) {
			if let maybeTok = *maybeMaybeTok {
				this.tokens.push(*maybeTok)
			}
		}
	}

	public function feed(input: String): void {
		for cp: CodePoint in input.items {
			this.feed(cp)
		}
	}

	public function end(): void {
		if let maybeMaybeTok = (*this.gen).next() {
			if let maybeTok = *maybeMaybeTok {
				this.tokens.push(*maybeTok)
			}
		}
	}
}
